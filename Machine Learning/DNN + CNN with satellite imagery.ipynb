{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://i67.tinypic.com/2jcbwcw.png)\n",
    "\n",
    "# Project Ocean Trash\n",
    "\n",
    "## Neural Network of Marine Debris data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** Jan Xu\n",
    "\n",
    "**Date:** Dec 1 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules and visualization packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Suppress TensorFlow and Keras warnings for cleaner output\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Debris</th>\n",
       "      <th>Trash1</th>\n",
       "      <th>NoTrash2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07/07/2012</td>\n",
       "      <td>-124.566667</td>\n",
       "      <td>48.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07/07/2012</td>\n",
       "      <td>-124.016667</td>\n",
       "      <td>48.283333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07/07/2012</td>\n",
       "      <td>-124.033333</td>\n",
       "      <td>48.316667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07/07/2012</td>\n",
       "      <td>-124.350000</td>\n",
       "      <td>48.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07/07/2012</td>\n",
       "      <td>-126.183333</td>\n",
       "      <td>44.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date           X          Y  Debris  Trash1  NoTrash2\n",
       "0  07/07/2012 -124.566667  48.383333       0       0         0\n",
       "1  07/07/2012 -124.016667  48.283333       0       0         0\n",
       "2  07/07/2012 -124.033333  48.316667       0       0         0\n",
       "3  07/07/2012 -124.350000  48.300000       1       0         0\n",
       "4  07/07/2012 -126.183333  44.900000       1       0         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataclass = pd.read_csv(\"Datasets/dataclass.csv\")\n",
    "dataclass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Debris</th>\n",
       "      <th>Trash1</th>\n",
       "      <th>NoTrash2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06/08/2012</td>\n",
       "      <td>-154.566667</td>\n",
       "      <td>27.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/01/2011</td>\n",
       "      <td>-155.500000</td>\n",
       "      <td>25.533300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date           X          Y  Debris  Trash1  NoTrash2\n",
       "0  06/08/2012 -154.566667  27.333333       1       1         0\n",
       "1  08/01/2011 -155.500000  25.533300       0       0         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep rows that have no satellite imagery\n",
    "newdata = dataclass.loc[dataclass[dataclass[\"Trash1\"]==1].index].append(dataclass.loc[dataclass[dataclass[\"NoTrash2\"]==1].index])\n",
    "newdata.rename({479:0, 618:1}, inplace=True)\n",
    "newdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import satellite imagery and normalize (divide by 18)\n",
    "\n",
    "T_band6 = pd.read_csv(\"Satellite Data ASTER/Trash1/band6.csv\").values // 18\n",
    "T_band7 = pd.read_csv(\"Satellite Data ASTER/Trash1/band7.csv\").values // 18\n",
    "NT_band6 = pd.read_csv(\"Satellite Data ASTER/NoTrash2/band6.csv\").values // 18\n",
    "NT_band7 = pd.read_csv(\"Satellite Data ASTER/NoTrash2/band7.csv\").values // 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2496, 2815)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_band6.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For DNN, reshape image shape to 1-D vector and concatenate band 6 with band 7 (as well as coordinates)\n",
    "\n",
    "For training purposes, the band 6 image is combined with the band 7 image, which will together with coordinates be the input features in our NN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14052482,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1 = np.concatenate([[newdata[\"X\"][0], newdata[\"Y\"][0]], T_band6.reshape(2496*2815,), T_band7.reshape(2496*2815,)])\n",
    "image2 = np.concatenate([[newdata[\"X\"][1], newdata[\"Y\"][1]], NT_band6.reshape(2496*2815,), NT_band7.reshape(2496*2815,)])\n",
    "image1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 14052482)\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create input vector\n",
    "x = np.stack([image1, image2])\n",
    "y = pd.get_dummies(newdata['Debris'].values).values\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normally we would do a train test split here, but since we only have two data points that seems a bit pathetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model initialization\n",
    "model = Sequential() # instantiate empty Sequential model\n",
    "\n",
    "# model contruction (architecture build computational graph)\n",
    "model.add(Dense(units=50, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=20, activation='sigmoid'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=2, activation='sigmoid'))\n",
    "\n",
    "# model compilation\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'sgd',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 79s 40s/step - loss: 1.0224 - acc: 0.5000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 38s 19s/step - loss: 0.5005 - acc: 0.5000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 33s 16s/step - loss: 0.5553 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 21s 11s/step - loss: 0.6232 - acc: 0.5000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 36s 18s/step - loss: 0.4624 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 36s 18s/step - loss: 0.5006 - acc: 0.5000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 35s 18s/step - loss: 0.6249 - acc: 0.5000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 30s 15s/step - loss: 0.7212 - acc: 0.5000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 36s 18s/step - loss: 0.3690 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 36s 18s/step - loss: 0.3356 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Fit the model by iterating over the training data in batches\n",
    "\n",
    "history = model.fit(x, y, epochs = 10, batch_size= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously DNN is very inefficient here for large images which are flattened to extremely long input vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4487477242946625\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x, y, verbose=0)\n",
    "print('Loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this is just to emphasize that all of this is just a proof of concept, and not a futile attempt to perform a neural network analysis with two pieces of inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try a CNN, where image shapes are retained\n",
    "\n",
    "For this model, ignore the coordinates as an input feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2496, 2815, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create input vector (based only on band 6 data)\n",
    "xCNN = np.stack([T_band6, NT_band6]).reshape(2, 2496, 2815, 1)\n",
    "xCNN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 310, 560, 16)      6416      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 291, 541, 32)      204832    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 36, 108, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 36, 108, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 124416)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                1990672   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 2,201,954\n",
      "Trainable params: 2,201,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Almost LeNet architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(20, 20),\n",
    "                 strides=(8,5),\n",
    "                 activation='sigmoid',\n",
    "                 input_shape=(2496, 2815, 1)))\n",
    "\n",
    "model.add(Conv2D(32, (20, 20), activation='sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(8, 5)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(16, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 22s 11s/step - loss: 0.8858 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 20s 10s/step - loss: 0.7479 - acc: 0.5000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 19s 10s/step - loss: 0.7556 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 17s 9s/step - loss: 0.5950 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 21s 11s/step - loss: 0.9270 - acc: 0.5000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 25s 13s/step - loss: 0.5961 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 15s 8s/step - loss: 0.6125 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.7143 - acc: 0.5000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 11s 6s/step - loss: 0.7939 - acc: 0.5000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 16s 8s/step - loss: 0.6577 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Fit the model by iterating over the training data in batches\n",
    "\n",
    "history = model.fit(xCNN, y, epochs=10, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6979650855064392\n",
      "Test accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "score = model.evaluate(xCNN, y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
